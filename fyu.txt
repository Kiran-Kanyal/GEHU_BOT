1> App.py

It initializes a Flask web app and sets up routes for serving static files, rendering the chatbot's UI, and processing chatbot responses.

It loads an intents.json file that contains predefined responses for different user messages.

It interacts with a chatbot model via predict_class() and get_response() functions (imported from chatbot.py) to generate responses.

Key Sections
Flask Initialization:

The app is instantiated with a static folder for serving assets.

Static File Serving:

The /static/<path:filename> route allows the server to deliver static content (e.g., images, CSS, JS files).

Home Route:

The root URL (/) renders chatbot.html, which is likely the user interface for interacting with the chatbot.

Chatbot Response Handling:

The /get_response route handles chatbot queries:

Extracts the user’s message from the request.

Uses predict_class() to classify the input.

Calls get_response() to generate an appropriate reply.

If multiple responses exist, it selects the first one.

Sends the bot’s response back in JSON format.

Running the Flask App:

The app runs in debug mode on port 5001, which is useful for development.







2> Chatbot.py

This chatbot.py file contains the core logic of your chatbot, handling natural language processing (NLP) and predicting responses based on user input. Here's a breakdown of how it works:

Overview
This script processes user input, predicts the correct intent using a trained model, and generates a response.

It relies on NLTK for text preprocessing and Keras for machine learning predictions.

It loads pretrained chatbot components from words.pkl, classes.pkl, and chatbot_model.h5 to classify messages.

Key Sections
Data Loading & Model Initialization

Imports essential libraries for NLP and deep learning.

Loads chatbot intents from intents.json.

Loads the word/token mappings (words.pkl) and intent classes (classes.pkl).

Loads the trained chatbot model (chatbot_model.h5) for intent classification.

Text Preprocessing

clean_up_sentence(sentence): Tokenizes the input sentence and applies lemmatization (reducing words to their base form).

bag_of_words(sentence): Converts tokenized words into a numerical representation (a "bag of words" array).

Intent Prediction

predict_class(sentence): Uses the trained model to predict the best matching intent for a given user message.

Filters low-confidence predictions with a threshold (ERROR_THRESHOLD = 0.25).

Sorts the predictions by probability and returns the most relevant intent.

Generating Chatbot Responses

get_response(intents_list, intents_json): Matches the predicted intent to predefined responses in intents.json.

Returns a random response from the matched intent category.

Console Testing

If run as a standalone script, the chatbot operates in a command-line interface, prompting the user for messages and displaying responses.

How It Works Together
The user enters a message.

The chatbot tokenizes and lemmatizes the input.

It converts the text into a bag-of-words representation.

The trained model predicts the intent.

The chatbot retrieves an appropriate response based on the predicted intent.

The bot replies with a predefined answer.






